{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### CNN Training - Train directly\n",
    "Tbd: Summary what happens in this notebook\n",
    "\n",
    "#### importing intern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from batchers import batcher\n",
    "from models.resnet_model import Hyperspectral_Resnet\n",
    "from utils.run import check_existing, run_extraction_on_models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### importing extern"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "import os\n",
    "from pprint import pprint\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### set root directory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# edit if necessary\n",
    "ROOT_DIR = 'C:/Users/matte/Documents/Data/01_Universitaet/02_TH_Koeln/06_Semester/04_Machine_Learning_Project/CNN_Architecture'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### set parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "DATASET_NAME = '2009-17'\n",
    "BATCH_SIZE = 128\n",
    "KEEP_FRAC = 1.0\n",
    "LABEL_NAME = 'wealthpooled'\n",
    "IS_TRAINING = False\n",
    "\n",
    "NAME = 'DHS_OOC'\n",
    "\n",
    "CKPTS_ROOT_DIR = os.path.join(ROOT_DIR, f'ckpts/{NAME}/')\n",
    "LOGS_ROOT_DIR  = os.path.join(ROOT_DIR, f'logs/{NAME}/')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### define `get_bands`\n",
    "get dictionary for bands"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_bands(bands: str):\n",
    "    return {\n",
    "        'ms': ('ms', None),\n",
    "        'msnl': ('ms', 'split'),\n",
    "        'nl': (None, 'split'),\n",
    "        'rgb': ('rgb', None),\n",
    "        'rgbnl': ('rgb', 'split'),\n",
    "    }[bands]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### set more parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# models to run\n",
    "ALL_MODELS = {}\n",
    "\n",
    "# best ResNet-18 transfer models\n",
    "TRANSFER_MODELS = {\n",
    "    'ResNet-18 RGB Transfer': {\n",
    "        'model_dir': 'transfer_2009-17nl_nlcenter_18preact_rgb_b64_fc001_conv001_lr0001',\n",
    "        'bands': ('rgb', None)\n",
    "    },\n",
    "    'ResNet-18 MS Transfer': {\n",
    "        'model_dir': 'transfer_2009-17nl_nlcenter_18preact_ms_b64_fc001_conv001_lr0001',\n",
    "        'bands': ('ms', None)\n",
    "    },\n",
    "}\n",
    "\n",
    "# ImageNet 'Transfer' Learning\n",
    "IMAGENET_TRANSFER_MODELS = [\n",
    "    '18preact_rgb_random',\n",
    "    '18preact_rgb_random2',\n",
    "    '18preact_rgb_random3',\n",
    "    '18preact_rgb_same',\n",
    "    '18preact_rgbnl_random',\n",
    "    '18preact_rgbnl_random2',\n",
    "    '18preact_rgbnl_random3',\n",
    "    '18preact_rgbnl_same',\n",
    "    '18preact_rgbnl_samecaled',\n",
    "    '18preact_ms_random',\n",
    "    '18preact_ms_random2',\n",
    "    '18preact_ms_random3',\n",
    "    '18preact_ms_same',\n",
    "    '18preact_ms_samecaled',\n",
    "    '18preact_msnl_random',\n",
    "    '18preact_msnl_random2',\n",
    "    '18preact_msnl_random3',\n",
    "    '18preact_msnl_same',\n",
    "    '18preact_msnl_samecaled',\n",
    "]\n",
    "\n",
    "# get parameters and bands for transfer models\n",
    "for model_dir in IMAGENET_TRANSFER_MODELS:\n",
    "    regex = r'18preact_(\\w+)_(\\w+)'\n",
    "    bands_name, init = re.match(regex, model_dir).groups()\n",
    "    bands_tup = get_bands(bands_name)\n",
    "    model_name = f'Resnet-18 {bands_name} Init {init}'\n",
    "    ALL_MODELS[model_name] = {\n",
    "        'model_dir': model_dir,\n",
    "        'bands': bands_tup\n",
    "    }\n",
    "\n",
    "# best ResNet-18 OOC End-to-End models\n",
    "OOC_MODEL_DIRS = [\n",
    "    # 6/14/2019\n",
    "    '2009-17A_18preact_ms_samescaled_b64_fc01_conv01_lr0001',\n",
    "    '2009-17B_18preact_ms_samescaled_b64_fc001_conv001_lr0001',\n",
    "    '2009-17C_18preact_ms_samescaled_b64_fc001_conv001_lr001',\n",
    "    '2009-17D_18preact_ms_samescaled_b64_fc001_conv001_lr01',\n",
    "    '2009-17E_18preact_ms_samescaled_b64_fc01_conv01_lr001',\n",
    "\n",
    "    # 10/7/2018\n",
    "    '2009-17A_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "    '2009-17B_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "    '2009-17C_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "    '2009-17D_18preact_nl_random_b64_fc1.0_conv1.0_lr01',\n",
    "    '2009-17E_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "\n",
    "    # 10/7/2018\n",
    "    '2009-17A_18preact_rgb_same_b64_fc001_conv001_lr01',\n",
    "    '2009-17B_18preact_rgb_same_b64_fc001_conv001_lr0001',\n",
    "    '2009-17C_18preact_rgb_same_b64_fc001_conv001_lr0001',\n",
    "    '2009-17D_18preact_rgb_same_b64_fc1.0_conv1.0_lr01',\n",
    "    '2009-17E_18preact_rgb_same_b64_fc001_conv001_lr0001',\n",
    "]\n",
    "\n",
    "# get parameters and bands for ooc models\n",
    "for model_dir in OOC_MODEL_DIRS:\n",
    "    regex = r'2009-17(\\w)_18preact_(\\w+)_\\w+_b64.+'\n",
    "    fold, bands_name = re.match(regex, model_dir).groups()\n",
    "    bands_tup = get_bands(bands_name)\n",
    "    model_name = f'Resnet-18 {bands_name} {fold}'\n",
    "    ALL_MODELS[model_name] = {\n",
    "        'model_dir': model_dir,\n",
    "        'bands': bands_tup\n",
    "    }\n",
    "\n",
    "# Incountry models\n",
    "INCOUNTRY_MODEL_DIRS = [\n",
    "    # 6/12/2019\n",
    "    'incountryA_18preact_ms_samescaled_b64_fc01_conv01_lr001',\n",
    "    'incountryB_18preact_ms_samescaled_b64_fc1_conv1_lr001',\n",
    "    'incountryC_18preact_ms_samescaled_b64_fc1.0_conv1.0_lr0001',\n",
    "    'incountryD_18preact_ms_samescaled_b64_fc001_conv001_lr0001',\n",
    "    'incountryE_18preact_ms_samescaled_b64_fc001_conv001_lr0001',\n",
    "\n",
    "    # May 2019\n",
    "    'incountryA_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "    'incountryB_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "    'incountryC_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "    'incountryD_18preact_nl_random_b64_fc1.0_conv1.0_lr0001',\n",
    "    'incountryE_18preact_nl_random_b64_fc01_conv01_lr001',\n",
    "]\n",
    "\n",
    "# get parameters and bands for incountry models\n",
    "for model_dir in INCOUNTRY_MODEL_DIRS:\n",
    "    regex = r'incountry(\\w)_18preact_(\\w+)_\\w+_b64.+'\n",
    "    fold, bands_name = re.match(regex, model_dir).groups()\n",
    "    bands_tup = get_bands(bands_name)\n",
    "    model_name = f'{NAME} Resnet-18 Incountry {bands_name} {fold}'\n",
    "    ALL_MODELS[model_name] = {\n",
    "        'model_dir': model_dir,\n",
    "        'bands': bands_tup\n",
    "    }\n",
    "\n",
    "# keep models\n",
    "KEEP_MODEL_DIRS = sorted(glob(os.path.join(LOGS_ROOT_DIR, '2009-17*_18preact_nl_random_keep*seed*')))\n",
    "\n",
    "for model_dir in KEEP_MODEL_DIRS:\n",
    "    model_dir = os.path.basename(model_dir)\n",
    "    regex = r'2009-17(\\w)_18preact_(\\w+)_\\w+_keep(.+)_seed(\\w+)_b64.+'\n",
    "    fold, bands_name, keep, seed = re.match(regex, model_dir).groups()\n",
    "    bands_tup = get_bands(bands_name)\n",
    "    model_name = f'Resnet-18 {bands_name} {fold}, keep{keep} seed{seed}'\n",
    "    ALL_MODELS[model_name] = {\n",
    "        'model_dir': model_dir,\n",
    "        'bands': bands_tup\n",
    "    }\n",
    "\n",
    "# set model parameters\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    'fc_reg': 5e-3,  # sustainlab: this doesn't actually matter\n",
    "    'conv_reg': 5e-3,  # sustainlab: this doesn't actually matter\n",
    "    'num_layers': 18,\n",
    "    'num_outputs': 1,\n",
    "    'is_training': IS_TRAINING,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### define `get_model_class`\n",
    "get model class or raise error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_model_class(model_type: str):\n",
    "    if model_type == 'resnet':\n",
    "        model_class = Hyperspectral_Resnet\n",
    "    elif model_type == 'vggf':\n",
    "        model_class = VGGF\n",
    "    elif model_type == 'simplecnn':\n",
    "        model_class = SimpleCNN\n",
    "    elif model_type == 'resnetcombo':\n",
    "        model_class = ResnetCombo\n",
    "    else:\n",
    "        raise ValueError('Unknown model_name. Was not one of [\"resnet\", \"vggf\", \"simplecnn\", \"resnetcombo\"].')\n",
    "    return model_class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### definde `get_batcher`\n",
    "get batcher, size and feed dictionary (tfrecord paths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_batcher(ls_bands: str, nl_band: str, num_epochs: int):\n",
    "    '''\n",
    "    Args\n",
    "    - ls_bands: one of [None, 'ms', 'rgb']\n",
    "    - nl_band: one of [None, 'merge', 'split']\n",
    "    - num_epochs: int\n",
    "    Returns\n",
    "    - b: Batcher\n",
    "    - size: int, length of dataset\n",
    "    - feed_dict: dict, feed_dict for initializing the dataset iterator\n",
    "    '''\n",
    "\n",
    "    # get tfrecord paths and dataset size\n",
    "    tfrecord_paths = np.asarray(batcher.get_tfrecord_paths(DATASET_NAME, 'all'))\n",
    "    size = len(tfrecord_paths)\n",
    "    tfrecord_paths_ph = tf.placeholder(tf.string, shape=[size])\n",
    "    feed_dict = {tfrecord_paths_ph: tfrecord_paths}\n",
    "\n",
    "    # get batcher\n",
    "    b = batcher.Batcher(\n",
    "        tfrecord_files=tfrecord_paths,\n",
    "        dataset=DATASET_NAME,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_name=LABEL_NAME,\n",
    "        num_threads=4,\n",
    "        epochs=num_epochs,\n",
    "        ls_bands=ls_bands,\n",
    "        nl_band=nl_band,\n",
    "        shuffle=False,\n",
    "        augment=False,\n",
    "        normalize=True,\n",
    "        cache=(num_epochs > 1))\n",
    "    return b, size, feed_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### define `main`\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def main():\n",
    "    # sustainlab: If any *.npz files already exist, print them out then throw an error\n",
    "    print('Checking all models for valid checkpoints and no existing *.npz files ...')\n",
    "    pprint(list(ALL_MODELS.keys()))\n",
    "    if not check_existing(ALL_MODELS,\n",
    "                          logs_root_dir=LOGS_ROOT_DIR,\n",
    "                          ckpts_root_dir=CKPTS_ROOT_DIR,\n",
    "                          save_filename='feaures.npz'):\n",
    "        print('Stopping')\n",
    "        return\n",
    "    print('Ready to go.')\n",
    "\n",
    "    # model configuration and parameter setting\n",
    "    models_by_config = defaultdict(list)\n",
    "    for model_name in ALL_MODELS:\n",
    "        model_info = ALL_MODELS[model_name]\n",
    "        ls_bands, nl_band = model_info['bands']\n",
    "        model_type = model_info.get('model_type', DEFAULT_MODEL_TYPE)\n",
    "        config = (ls_bands, nl_band, model_type)\n",
    "        models_by_config[config].append(model_info)\n",
    "\n",
    "    # print configuration\n",
    "    for config, model_infos in models_by_config.items():\n",
    "        ls_bands, nl_band, model_type = config\n",
    "        print('====== Current Config: ======')\n",
    "        print('- ls_bands:', ls_bands)\n",
    "        print('- nl_band:', nl_band)\n",
    "        print('- model_type:', model_type)\n",
    "        print('- number of models:', len(model_infos))\n",
    "        print()\n",
    "\n",
    "    # get batcher, dataset size and feed_dict\n",
    "    b, size, feed_dict = get_batcher(ls_bands=ls_bands, nl_band=nl_band,\n",
    "                                     num_epochs=len(model_infos))\n",
    "\n",
    "    # calculate batches per epoch\n",
    "    batches_per_epoch = int(np.ceil(size / BATCH_SIZE))\n",
    "\n",
    "    # run feature extraction\n",
    "    run_extraction_on_models(\n",
    "        model_infos,\n",
    "        ModelClass = get_model_class(model_type),\n",
    "        model_params = MODEL_PARAMS,\n",
    "        batcher = b,\n",
    "        batches_per_epoch = batches_per_epoch,\n",
    "        logs_root_dir = LOGS_ROOT_DIR,\n",
    "        ckpts_root_dir = CKPTS_ROOT_DIR,\n",
    "        save_filename = 'features.npz',\n",
    "        batch_keys = ['labels', 'locs', 'years'],\n",
    "        feed_dict = feed_dict\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### run main"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking all models for valid checkpoints and no existing *.npz files ...\n",
      "['Resnet-18 rgb Init random',\n",
      " 'Resnet-18 rgb Init random2',\n",
      " 'Resnet-18 rgb Init random3',\n",
      " 'Resnet-18 rgb Init same',\n",
      " 'Resnet-18 rgbnl Init random',\n",
      " 'Resnet-18 rgbnl Init random2',\n",
      " 'Resnet-18 rgbnl Init random3',\n",
      " 'Resnet-18 rgbnl Init same',\n",
      " 'Resnet-18 rgbnl Init samecaled',\n",
      " 'Resnet-18 ms Init random',\n",
      " 'Resnet-18 ms Init random2',\n",
      " 'Resnet-18 ms Init random3',\n",
      " 'Resnet-18 ms Init same',\n",
      " 'Resnet-18 ms Init samecaled',\n",
      " 'Resnet-18 msnl Init random',\n",
      " 'Resnet-18 msnl Init random2',\n",
      " 'Resnet-18 msnl Init random3',\n",
      " 'Resnet-18 msnl Init same',\n",
      " 'Resnet-18 msnl Init samecaled',\n",
      " 'Resnet-18 ms A',\n",
      " 'Resnet-18 ms B',\n",
      " 'Resnet-18 ms C',\n",
      " 'Resnet-18 ms D',\n",
      " 'Resnet-18 ms E',\n",
      " 'Resnet-18 nl A',\n",
      " 'Resnet-18 nl B',\n",
      " 'Resnet-18 nl C',\n",
      " 'Resnet-18 nl D',\n",
      " 'Resnet-18 nl E',\n",
      " 'Resnet-18 rgb A',\n",
      " 'Resnet-18 rgb B',\n",
      " 'Resnet-18 rgb C',\n",
      " 'Resnet-18 rgb D',\n",
      " 'Resnet-18 rgb E',\n",
      " 'DHS_OOC Resnet-18 Incountry ms A',\n",
      " 'DHS_OOC Resnet-18 Incountry ms B',\n",
      " 'DHS_OOC Resnet-18 Incountry ms C',\n",
      " 'DHS_OOC Resnet-18 Incountry ms D',\n",
      " 'DHS_OOC Resnet-18 Incountry ms E',\n",
      " 'DHS_OOC Resnet-18 Incountry nl A',\n",
      " 'DHS_OOC Resnet-18 Incountry nl B',\n",
      " 'DHS_OOC Resnet-18 Incountry nl C',\n",
      " 'DHS_OOC Resnet-18 Incountry nl D',\n",
      " 'DHS_OOC Resnet-18 Incountry nl E']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "did not find checkpoint matching: C:/Users/matte/Documents/Data/01_Universitaet/02_TH_Koeln/06_Semester/04_Machine_Learning_Project/CNN_Architecture\\ckpts/DHS_OOC/18preact_rgb_random\\ckpt-*",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-c7bc734e5e35>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'__main__'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[0mmain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-15-38dccb576d14>\u001B[0m in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m                           \u001B[0mlogs_root_dir\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mLOGS_ROOT_DIR\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m                           \u001B[0mckpts_root_dir\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mCKPTS_ROOT_DIR\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m                           save_filename='feaures.npz'):\n\u001B[0m\u001B[0;32m      9\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Stopping'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[1;32mreturn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\Data\\01_Universitaet\\02_TH_Koeln\\06_Semester\\04_Machine_Learning_Project\\CNN_Architecture\\utils\\run.py\u001B[0m in \u001B[0;36mcheck_existing\u001B[1;34m(models, logs_root_dir, ckpts_root_dir, save_filename)\u001B[0m\n\u001B[0;32m    228\u001B[0m         \u001B[1;31m# check that checkpoint exists\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    229\u001B[0m         \u001B[0mckpt_glob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mckpts_root_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'ckpt-*'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 230\u001B[1;33m         \u001B[1;32massert\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mglob\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mckpt_glob\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34mf'did not find checkpoint matching: {ckpt_glob}'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    231\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    232\u001B[0m         \u001B[0mnpz_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlogs_root_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_filename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: did not find checkpoint matching: C:/Users/matte/Documents/Data/01_Universitaet/02_TH_Koeln/06_Semester/04_Machine_Learning_Project/CNN_Architecture\\ckpts/DHS_OOC/18preact_rgb_random\\ckpt-*"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}