{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import sklearn.cluster\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import scipy.spatial\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from models/histograms.py\n",
    "def get_per_image_histograms(init_iter, batch_op, band_bin_edges):\n",
    "    '''\n",
    "    Args\n",
    "    - iter_init: tf op, initializes the dataset iterator\n",
    "    - batch_op: dict, str => tf.Tensor\n",
    "      - 'images': tf.Tensor, shape [batch_size, 224, 224, C], last channel is nightlights\n",
    "      - 'labels': tf.Tensor, shape [batch_size]\n",
    "      - 'locs': tf.Tensor, shape [batch_size, 2]\n",
    "      - 'years': tf.Tensor, shape [batch_size]\n",
    "    - band_bin_edges\n",
    "\n",
    "    Returns: results, dict\n",
    "    - 'image_hists': np.array, shape [N, C, nbins], type int64\n",
    "    - 'labels': np.array, shape [N], type float32, all labels\n",
    "    - 'locs': np.array, shape [N, 2], type float32, all locs\n",
    "    - 'years': np.array, shape [N], type int32, year for each image\n",
    "    - 'nls_center': np.array, shape [N], type float32, center nightlight value\n",
    "    - 'nls_mean': np.array, shape [N], type float32, mean nightlight value\n",
    "    '''\n",
    "    keys = ['image_hists', 'labels', 'locs', 'years', 'nls_center', 'nls_mean']\n",
    "    results = {k: [] for k in keys}\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_iter)\n",
    "        try:\n",
    "            batch_num = 1\n",
    "            while True:\n",
    "                batch = sess.run(batch_op)\n",
    "                results['labels'].append(batch['labels'])\n",
    "                results['locs'].append(batch['locs'])\n",
    "                results['years'].append(batch['years'])\n",
    "\n",
    "                images = batch['images']\n",
    "\n",
    "                # calculate scalar nightlights\n",
    "                nl_center = images[:, 111, 111, -1]\n",
    "                results['nls_center'].append(nl_center)\n",
    "                nl_mean = np.mean(images[:, :, :, -1], axis=(1, 2))\n",
    "                results['nls_mean'].append(nl_mean)\n",
    "\n",
    "                # create image histograms\n",
    "                num_images = images.shape[0]\n",
    "                num_bands = images.shape[3]\n",
    "                for n in range(num_images):\n",
    "                    image_hists = []\n",
    "                    image = images[n, :, :, :]\n",
    "                    for b in range(num_bands):\n",
    "                        band = image[:, :, b]\n",
    "                        hist, _ = np.histogram(band, bins=band_bin_edges)\n",
    "                        image_hists.append(hist)\n",
    "\n",
    "                    image_hists = np.stack(image_hists)\n",
    "                    results['image_hists'].append(image_hists)\n",
    "                print('Finished batch', batch_num)\n",
    "                batch_num += 1\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "\n",
    "    results['image_hists'] = np.stack(results['image_hists'])\n",
    "    for k in ['labels', 'locs', 'years', 'nls_center', 'nls_mean']:\n",
    "        results[k] = np.concatenate(results[k])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a5d883e8c69e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# THIS REQUIRES >= 35 GB RAM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtfrecord_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tfrecord_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDATASET_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0minit_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfrecord_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_per_image_histograms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mband_bin_edges\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBAND_BIN_EDGES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batcher' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = '../data/dhs_image_hists2.npz'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    # THIS REQUIRES >= 35 GB RAM\n",
    "    tfrecord_paths = batcher.get_tfrecord_paths(dataset=DATASET_NAME, split='all')\n",
    "    init_iter, batch_op = get_batcher(tfrecord_paths).get_batch()\n",
    "    results = get_per_image_histograms(init_iter, batch_op, band_bin_edges=BAND_BIN_EDGES)\n",
    "    print('Saving image histograms to', file_path)\n",
    "    np.savez_compressed(file_path, **results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loc_dict(loc_dict_path):\n",
    "    '''\n",
    "    Args\n",
    "    - loc_dict_path: str, path to save the loc_dict\n",
    "    '''\n",
    "    surveys_df = pd.read_csv('../data/dhs_wealth_index.csv', float_precision='high')\n",
    "    surveys_df.rename({'LATNUM': 'lat', 'LONGNUM': 'lon', 'URBAN_RURA': 'urban'},\n",
    "                      axis='columns', inplace=True)\n",
    "    for col in ['lat', 'lon', 'wealthpooled', 'wealth', 'wealthpooled5country']:\n",
    "        surveys_df[col] = surveys_df[col].astype(np.float32)\n",
    "    surveys_df['country'] = (surveys_df['country']\n",
    "                             .str.lower()\n",
    "                             .str.replace(' ', '_')\n",
    "                             .str.replace(\"'\", '_'))\n",
    "\n",
    "    loc_dict = {}\n",
    "    for (lat, lon) in locs:\n",
    "        loc = (lat, lon)\n",
    "        row = surveys_df.loc[(surveys_df['lat'] == lat) & (surveys_df['lon'] == lon), :]\n",
    "        assert len(row) == 1\n",
    "        row = row.iloc[0]\n",
    "\n",
    "        cy = '{c}_{y}'.format(c=row['country'], y=row['svyid'][-4:])\n",
    "\n",
    "        assert loc not in loc_dict\n",
    "        loc_dict[loc] = {\n",
    "            'cluster': row['cluster'],\n",
    "            'country': row['country'],\n",
    "            'country_year': cy,  # surveyID\n",
    "            'households': row['households'],\n",
    "            'urban': row['urban'] == 'U',\n",
    "            'wealth': row['wealth'],\n",
    "            'wealthpooled': row['wealthpooled'],\n",
    "            'year': row['year']\n",
    "        }\n",
    "\n",
    "    with open(loc_dict_path, 'wb') as f:\n",
    "        pickle.dump(loc_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = ['A', 'B', 'C', 'D', 'E']\n",
    "SPLITS = ['train', 'val', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = npz['labels']\n",
    "locs = npz['locs']\n",
    "years = npz['years']\n",
    "nls_center = npz['nls_center']\n",
    "nls_mean = npz['nls_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'locs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-08dbbed9c1e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcreate_loc_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc_dict_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-7e62b6135d0f>\u001b[0m in \u001b[0;36mcreate_loc_dict\u001b[1;34m(loc_dict_path)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mloc_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurveys_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msurveys_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msurveys_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lon'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'locs' is not defined"
     ]
    }
   ],
   "source": [
    "loc_dict_path = '../data/dhs_loc_dict.pkl'\n",
    "\n",
    "if not os.path.exists(loc_dict_path):\n",
    "    create_loc_dict(loc_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(loc_dict_path, 'rb') as f:\n",
    "    loc_dict = pickle.load(f)\n",
    "    \n",
    "loc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from sustainlab: data_analysis/create_folds.py\n",
    "def create_folds(locs, min_dist, dist_metric, fold_names, verbose=True,\n",
    "                 plot_largest_clusters=0):\n",
    "    '''Partitions locs into folds.\n",
    "\n",
    "    Args\n",
    "    - locs: np.array, shape [N, 2]\n",
    "    - min_dist: float, minimum distance between folds\n",
    "    - dist_metric: str, a valid distance metric accepted by sklearn.cluster.dbscan\n",
    "    - fold_names: list of str, names of folds\n",
    "    - verbose: bool\n",
    "    - plot_largest_clusters: int, number of largest clusters to plot\n",
    "\n",
    "    Returns\n",
    "    - locs_to_indices: dict, maps (lat, lon) tuple to index in locs np.array\n",
    "    - folds: dict, fold name => np.array of indices of locs belonging to that fold\n",
    "    '''\n",
    "    # there are duplicate locs => we want to cluster based on unique locs\n",
    "    locs_to_indices = defaultdict(list)\n",
    "    for i, loc in enumerate(locs):\n",
    "        locs_to_indices[tuple(loc)].append(i)\n",
    "\n",
    "    unique_locs = np.unique(locs, axis=0)  # get unique rows\n",
    "\n",
    "    # any point within `min_dist` of another point belongs to the same cluster\n",
    "    # - cluster_labels assigns a cluster index (0-indexed) to each loc\n",
    "    # - a cluster label of -1 means that the point is an outlier\n",
    "    _, cluster_labels = sklearn.cluster.dbscan(\n",
    "        X=unique_locs, eps=min_dist, min_samples=2, metric=dist_metric)\n",
    "\n",
    "    if verbose:\n",
    "        _, unique_counts = np.unique(cluster_labels, return_counts=True)\n",
    "\n",
    "        print('num clusters:', np.max(cluster_labels) + 1)  # clusters are 0-indexed\n",
    "        print('max cluster size:', np.max(unique_counts[1:]))  # exclude outliers\n",
    "        print('num outliers:', np.sum(cluster_labels == -1))\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=[4, 2.5], constrained_layout=True)\n",
    "        ax.hist(unique_counts[1:], bins=50)  # exclude outliers\n",
    "        ax.set(xlabel='cluster size', ylabel='count')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title('histogram of cluster sizes (excluding outliers)')\n",
    "        ax.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # mapping: cluster number => list of indices of points in that cluster\n",
    "    # - if cluster label is -1 (outlier), then treat that unique loc as its own cluster\n",
    "    neg_counter = -1\n",
    "    clusters_dict = defaultdict(list)\n",
    "    for loc, c in zip(unique_locs, cluster_labels):\n",
    "        indices = locs_to_indices[tuple(loc)]\n",
    "        if c < 0:\n",
    "            c = neg_counter\n",
    "            neg_counter -= 1\n",
    "        clusters_dict[c].extend(indices)\n",
    "\n",
    "    # sort clusters by descending cluster size\n",
    "    sorted_clusters = sorted(clusters_dict.keys(), key=lambda c: -len(clusters_dict[c]))\n",
    "\n",
    "    # plot the largest clusters\n",
    "    for i in range(plot_largest_clusters):\n",
    "        c = sorted_clusters[i]\n",
    "        indices = clusters_dict[c]\n",
    "        title = 'cluster {c}: {n} points'.format(c=c, n=len(indices))\n",
    "        plot_locs(locs[indices], figsize=(4, 4), title=title)\n",
    "\n",
    "    # greedily assign clusters to folds\n",
    "    folds = {f: [] for f in fold_names}\n",
    "    for c in sorted_clusters:\n",
    "        # assign points in cluster c to smallest fold\n",
    "        f = min(folds, key=lambda f: len(folds[f]))\n",
    "        folds[f].extend(clusters_dict[c])\n",
    "\n",
    "    for f in folds:\n",
    "        folds[f] = np.sort(folds[f])\n",
    "\n",
    "    return locs_to_indices, folds\n",
    "\n",
    "def verify_folds(folds, locs, min_dist, dist_metric, max_index=None):\n",
    "    '''Verifies that folds do not overlap.\n",
    "\n",
    "    Args\n",
    "    - folds: dict, fold name => np.array of indices of locs belonging to that fold\n",
    "    - locs: np.array, shape [N, 2], each row is [lat, lon]\n",
    "    - min_dist: float, minimum distance between folds\n",
    "    - dist_metric: str, a valid distance metric accepted by sklearn.cluster.dbscan\n",
    "    - max_index: int, all indices in range(max_index) should be included\n",
    "    '''\n",
    "    for fold, idxs in folds.items():\n",
    "        assert np.all(np.diff(idxs) >= 0)  # check that indices are sorted\n",
    "\n",
    "    # check that all indices are included\n",
    "    if max_index is not None:\n",
    "        assert np.array_equal(\n",
    "            np.sort(np.concatenate(list(folds.values()))),\n",
    "            np.arange(max_index))\n",
    "\n",
    "    # check to ensure no overlap\n",
    "    for a, b in itertools.combinations(folds.keys(), r=2):\n",
    "        a_idxs = folds[a]\n",
    "        b_idxs = folds[b]\n",
    "        dists = scipy.spatial.distance.cdist(locs[a_idxs], locs[b_idxs], metric=dist_metric)\n",
    "        assert np.min(dists) > min_dist\n",
    "        print(a, b, np.min(dists))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from sustainlab: utils/get_plot.py\n",
    "def setup_ax(fig, pos=(1, 1, 1)):\n",
    "    '''\n",
    "    Args\n",
    "    - fig: matplotlib.figure.Figure\n",
    "    - pos: 3-tuple of int, axes position (nrows, ncols, index)\n",
    "\n",
    "    Returns: matplotlib.axes.Axes\n",
    "    '''\n",
    "    ax = fig.add_subplot(*pos, projection=ccrs.PlateCarree())\n",
    "\n",
    "    # draw land (better version of cfeature.LAND)\n",
    "    # land = cfeature.NaturalEarthFeature(\n",
    "    #     category='physical', name='land', scale='10m',\n",
    "    #     edgecolor='face', facecolor=cfeature.COLORS['land'], zorder=-1)\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "\n",
    "    # draw borders of countries (better version of cfeature.BORDERS)\n",
    "    countries = cfeature.NaturalEarthFeature(\n",
    "        category='cultural', name='admin_0_boundary_lines_land', scale='10m',\n",
    "        edgecolor='black', facecolor='none')\n",
    "    ax.add_feature(countries)\n",
    "\n",
    "    # draw coastline (better version of cfeature.COASTLINE)\n",
    "    coastline = cfeature.NaturalEarthFeature(\n",
    "        category='physical', name='coastline', scale='10m',\n",
    "        edgecolor='black', facecolor='none')\n",
    "    ax.add_feature(coastline)\n",
    "\n",
    "    # draw lakes (better version of cfeature.LAKES)\n",
    "    lakes = cfeature.NaturalEarthFeature(\n",
    "        category='physical', name='lakes', scale='10m',\n",
    "        edgecolor='face', facecolor=cfeature.COLORS['water'])\n",
    "    ax.add_feature(lakes)\n",
    "\n",
    "    # draw ocean (better version of cfeature.OCEAN)\n",
    "    ocean = cfeature.NaturalEarthFeature(\n",
    "        category='physical', name='ocean', scale='50m',\n",
    "        edgecolor='face', facecolor=cfeature.COLORS['water'], zorder=-1)\n",
    "    ax.add_feature(ocean)\n",
    "\n",
    "    # draw rivers (better version of cfeature.RIVERS)\n",
    "    rivers = cfeature.NaturalEarthFeature(\n",
    "        category='physical', name='rivers_lake_centerlines', scale='10m',\n",
    "        edgecolor=cfeature.COLORS['water'], facecolor='none')\n",
    "    ax.add_feature(rivers)\n",
    "\n",
    "    # draw borders of states/provinces internal to a country\n",
    "    states_provinces = cfeature.NaturalEarthFeature(\n",
    "        category='cultural', name='admin_1_states_provinces_lines', scale='50m',\n",
    "        edgecolor='gray', facecolor='none')\n",
    "    ax.add_feature(states_provinces)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    gridliner = ax.gridlines(draw_labels=True)\n",
    "    gridliner.xlabels_top = False\n",
    "    gridliner.ylabels_right = False\n",
    "    return ax\n",
    "\n",
    "def plot_locs(locs, fig=None, pos=(1, 1, 1), figsize=(15, 15), title=None,\n",
    "              colors=None, cbar_label=None, show_cbar=True, **scatter_kws):\n",
    "    '''\n",
    "    Args\n",
    "    - locs: np.array, shape [N, 2], each row is [lat, lon]\n",
    "    - fig: matplotlib.figure.Figure\n",
    "    - pos: 3-tuple of int, axes position (nrows, ncols, index)\n",
    "    - figsize: list, [width, height] in inches, only used if fig is None\n",
    "    - title: str\n",
    "    - colors: list of int, length N\n",
    "    - cbar_label: str, label for the colorbar\n",
    "    - show_cbar: bool, whether to show the colorbar\n",
    "    - scatter_kws: other arguments for ax.scatter\n",
    "\n",
    "    Returns: matplotlib.axes.Axes\n",
    "    '''\n",
    "    if fig is None:\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "    ax = setup_ax(fig, pos)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    if 's' not in scatter_kws:\n",
    "        scatter_kws['s'] = 2\n",
    "    pc = ax.scatter(locs[:, 1], locs[:, 0], c=colors, **scatter_kws)\n",
    "    if colors is not None and show_cbar:\n",
    "        cbar = fig.colorbar(pc, ax=ax, fraction=0.03)\n",
    "        if cbar_label is not None:\n",
    "            cbar.set_label(cbar_label)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_incountry_folds(locs, folds_path):\n",
    "    '''\n",
    "    Args\n",
    "    - locs: np.array, shape [N, 2], each row is [lat, lon]\n",
    "    - folds_path: str, path to save incountry folds dict\n",
    "    '''\n",
    "    MIN_DIST = 0.092841  # sqrt(0.060570**2 + 0.070361**2)\n",
    "    DIST_METRIC = 'euclidean'\n",
    "    MAX_INDEX = 19669\n",
    "\n",
    "    locs_to_indices, test_folds = create_folds(\n",
    "        locs, min_dist=MIN_DIST, dist_metric=DIST_METRIC, fold_names=FOLDS,\n",
    "        plot_largest_clusters=5)\n",
    "    verify_folds(test_folds, locs=locs, min_dist=MIN_DIST,\n",
    "                 dist_metric=DIST_METRIC, max_index=MAX_INDEX)\n",
    "\n",
    "    print('Size of each fold')\n",
    "    pprint({f: len(indices) for f, indices in test_folds.items()})\n",
    "\n",
    "    # create train/val/test splits\n",
    "    folds = {}\n",
    "    for i, f in enumerate(FOLDS):\n",
    "        folds[f] = {}\n",
    "        folds[f]['test'] = test_folds[f]\n",
    "\n",
    "        val_f = FOLDS[(i+1) % 5]\n",
    "        folds[f]['val'] = test_folds[val_f]\n",
    "\n",
    "        train_fs = [FOLDS[(i+2) % 5], FOLDS[(i+3) % 5], FOLDS[(i+4) % 5]]\n",
    "        folds[f]['train'] = np.sort(np.concatenate([test_folds[f] for f in train_fs]))\n",
    "\n",
    "    if os.path.exists(folds_path):\n",
    "        with open(folds_path, 'rb') as f:\n",
    "            existing_folds = pickle.load(f)\n",
    "        for f in FOLDS:\n",
    "            for s in SPLITS:\n",
    "                assert np.array_equal(folds[f][s], existing_folds[f][s])\n",
    "    else:\n",
    "        with open(folds_path, 'wb') as f:\n",
    "            pickle.dump(folds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ooc_folds = {\n",
    "    f: {split: [] for split in SPLITS}\n",
    "    for f in FOLDS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incountry_folds_path = '../data/dhs_incountry_folds.pkl'\n",
    "\n",
    "create_incountry_folds(locs, incountry_folds_path)\n",
    "with open(incountry_folds_path, 'rb') as f:\n",
    "    incountry_folds = pickle.load(f)\n",
    "\n",
    "pprint({\n",
    "    f: {split: len(incountry_folds[f][split])\n",
    "        for split in SPLITS}\n",
    "    for f in ooc_folds\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
